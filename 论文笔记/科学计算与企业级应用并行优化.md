串行CSR格式稀疏矩阵向量乘

```
inline void smmSerial(const int numRows,const int *rowIndex,
const int &columnIndex,const float *val,const float *x,float *r)
{
	int rowStart;
	int rowEnd;
	for(int i = 0;i < numRows;i++)
	{
		rowStart = rowIndex[i];
		rowEnd = rowIndex[i+1];
		float sum = 0.0f;
		for(int j = rowStart;j < rowEnd;j++)
		{
			sum += val[j] * x[columnIndex[j]];
		}
		r[i] = sum;
	}
}
```

使用openMP优化，那么不同行非零元素数量可能差别巨大，那么需要使用动态负载均衡。

```
inline void smmSerial(const int numRows,const int *rowIndex,
const int &columnIndex,const float *val,const float *x,float *r)
{
	int rowStart;
	int rowEnd;
#pragma omp parallel for private(rowStart,rowEnd) schedule(dynamc:size)
	for(int i = 0;i < numRows;i++)
	{
		rowStart = rowIndex[i];
		rowEnd = rowIndex[i+1];
		float sum = 0.0f;
		for(int j = rowStart;j < rowEnd;j++)
		{
			sum += val[j] * x[columnIndex[j]];
		}
		r[i] = sum;
	}
}
```

在行内非零元数目不等时会引起大量的warp内分支发散

要获取线程的索引

```
__global__
void vecAddKernel (float *A , float *B , float * C , int n)
{
    int index = blockIdx.x * blockDim.x + threadIdx.x;
    if (index < n)
    {
        C[index] = A[index] + B[index] ;
    }
}
```

在硬件这一方面，线程块由warp组成。一个warp由一个线程块中的32个线程组成，其中那32个线程都执行相同的指令

网格由块组成，这些块都是独立的。块由线程组成，线程又可以组成warp，32个同一个块中的线程组成warp，而CUDA的指令用于在warp上执行。

The main thing to notice here is that a GPU is really an array of SMs, each of which has N cores. Each SM has accesss to some thing called a register file, which is much like a chunk of memory that runs at the same speed as the SP units.

​	Each SM has a separate bus into the texture memory, constant memory, and global memory space.

可以这么说，军队有很多士兵(线程)，军队可以分为很多师团(块)，而块又可以分成很多连(warp)。

CPU每个核心都有少量的寄存，用于执行给定的任务，因此需要在任务之间进行context switching，但是对CPU来说很耗时，因为需要将整个寄存器集存在RAM中，并且下一次还需要从RAM中拿出来。但GPU并不仅有一组寄存器，而是有很多组寄存器，所谓context switching就是从一组寄存器换到另一组寄存器。

CPU需要面对stall问题，如果有很多线程，或者说是很多小任务，那么CPU将把时间花在上下文切换间，性能将会下降。

而GPU就是专门解决stall问题的，如果有个线程必须要等待计算结果，那么GPU会让这个线程先去干别的事，之后再处理这个计算结果。

cuda programming a deve

CPU程序

```
void some_func(void)
{
	int i;
	for(i = 0;i < 128;i++)
	{
		a[i] = b[i] * c[i];
	}
}
```

CUDA程序

```
__global__ void some_kernel_func(int *const a,const int * const b,const int * const c)
{
	const unsigned int thread_idx = threadIdx.x;
	const unsigned int thread_idx = blockIdx.x * blockDim.x + threadIdx.x;
	a[thread_idx] = b[thread_idx] * c[thread_idx];
}
```

例子

```
#include <stdio.h>
#include <stdlib.h>
#include <conio.h>

__global__ void what_is_my_id(unsigned int * const block,
				unsigned int * const thread,
				unsigned int * const warp,
				unsigned int * const calc_thread)
{
	const unsigned int thread_idx = (blockIdx.x * blockDim.x) + threadIdx.x;
	block[thread_idx] = blockIdx.x;
	thread[thread_idx] = threadIdx.x;
	warp[thread_idx] = threadIdx.x / warpSize;
	calc_thread[thread_idx] = thread_idx;
}

#define ARRAY_SIZE 128
#define ARRAY_SIZE_IN_BYTES (sizeof(unsigned int)*(ARRAY_SIZE))

unsigned int cpu_block[ARRAY_SIZE];
unsigned int cpu_thread[ARRAY_SIZE];
unsigned int cpu_warp[ARRAY_SIZE];
unsigned int cpu_calc_thread[ARRAY_SIZE];

int main()
{
	const unsigned int num_blocks = 2;
	const unsigned int num_threads = 64;
	char ch;
	
	unsigned int * gpu_block;
	unsigned int * gpu_thread;
	unsigned int * gpu_warp;
	unsigned int * gpu_calc_thread;
	
	unsigned int i;
	
	cudaMalloc((void**) & gpu_block,ARRAY_SIZE_IN_BYTES);
	cudaMalloc((void**) & gpu_thread,ARRAY_SIZE_IN_BYTES);
	cudaMalloc((void**) & gpu_warp,ARRAY_SIZE_IN_BYTES);
	cudaMalloc((void**) & gpu_calc_thread,ARRAY_SIZE_IN_BYTES);
	
	what_is_my_id<<<num_blocks,num_threads>>>(gpu_block,gpu_thread,
											gpu_warp,gpu_thread);
	cudaMemcpy(cpu_block,gpu_block,ARRAY_SIZE_IN_BYTES,
				cudaMemcpyDeviceToHost);
	cudaMemcpy(cpu_thread,gpu_thread,ARRAY_SIZE_IN_BYTES,
				cudaMemcpyDeviceToHost);
	cudaMemcpy(cpu_warp,gpu_warp,ARRAY_SIZE_IN_BYTES,
				cudaMemcpyDeviceToHost);
	cudaMemcpy(cpu_calc_thread,gpu_calc_thread,ARRAY_SIZE_IN_BYTES,
				cudaMemcpyDeviceToHost);
				
	cudaFree(gpu_block);
	cudaFree(gpu_thread);
	cudaFree(gpu_warp);
	cudaFree(gpu_calc_thread);
	
	for (i = 0; i < ARRAY_SIZE; iþþ)
	{
	printf("Calculated Thread: %3u - Block: %2u - Warp %2u - Thread %3u\n",
	cpu_calc_thread[i], cpu_block[i], cpu_warp[i], cpu_thread[i]);
	}
	ch = getch();
}
```

